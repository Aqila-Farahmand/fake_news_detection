{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Required Libraries\n"
   ],
   "metadata": {
    "id": "fxiA1oNssM2-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "id": "hs1IMiUVsZzO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "outputId": "dd818528-9d2a-4d41-ae82-0adb32807ccc",
    "ExecuteTime": {
     "end_time": "2025-02-18T10:33:14.493217Z",
     "start_time": "2025-02-18T10:33:11.921532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (4.32.1)\r\n",
      "Requirement already satisfied: filelock in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\r\n",
      "Requirement already satisfied: requests in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aqilafarahmand/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\""
   ],
   "metadata": {
    "id": "D9GJ-oofr8ZO",
    "ExecuteTime": {
     "end_time": "2025-02-18T10:33:15.007177Z",
     "start_time": "2025-02-18T10:33:14.494970Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdamW\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, Dataset\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Dataset\n",
    "\n",
    "Load the dataset into a pandas DataFrame"
   ],
   "metadata": {
    "id": "GcBVA15rscR3"
   }
  },
  {
   "cell_type": "code",
   "source": "dataset = pd.read_csv('news_dataset.csv')",
   "metadata": {
    "id": "zxuSojQnsYLG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rdqucTjemGqn",
    "outputId": "71ff14fb-8138-495a-b12b-b73f2f20a8cc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.shape"
   ],
   "metadata": {
    "id": "Neew3S5YkBAm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b359a8ce-143f-44a5-b3ee-99642c03a785"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "id": "u1vQQg6opghb"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.dropna(inplace=True)"
   ],
   "metadata": {
    "id": "c0-eeQKO6HIC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.shape"
   ],
   "metadata": {
    "id": "Y1IJ_3ecpkIp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "h4uxYFmtaN72",
    "outputId": "e61de311-7e9c-4351-f904-ca5127ff9456"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Rename the dataset class column to labels**"
   ],
   "metadata": {
    "id": "3vZ2WCRPqzMx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[\"class\"] = dataset[\"labels\"]"
   ],
   "metadata": {
    "id": "I-zF6hG-aXwA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.head()"
   ],
   "metadata": {
    "id": "-gydIASXuPqY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the data into training, validation and test sets\n"
   ],
   "metadata": {
    "id": "t9h859kos6k1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# train-temp split (80:20)\n",
    "\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# validation-test split (10:10) -> 80:10:10\n",
    "\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n"
   ],
   "metadata": {
    "id": "sAo8VktUps4u"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "id": "KX1ZqTwUsxE6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_data.shape"
   ],
   "metadata": {
    "id": "1XUwN-NnsnOf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "id": "qdofl3VXrk-H"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "val_data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pRQsKZ5Nu_em",
    "outputId": "3555ad94-f6b6-4b06-eb80-7ccc472f9513"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "val_data.shape"
   ],
   "metadata": {
    "id": "f0Yd6V7WsZyC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "''' This class takes in the data, tokenizes it using the AutoTokenizer for our MODEL_NAME,\n",
    " and returns the input IDs, attention masks, and labels.'''\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, data, max_len=128):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['text']\n",
    "        labels = self.data.iloc[index]['labels']\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0), torch.tensor(labels, dtype=torch.long)"
   ],
   "metadata": {
    "id": "9-4ULm_Ps1f_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader\n",
    "\n",
    "Create a DataLoader for the training and test datasets so the data is iterated as batches"
   ],
   "metadata": {
    "id": "UU4stKlSmkiR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = FakeNewsDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = FakeNewsDataset(val_data)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "id": "qoRnpQ_4tYr6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model\n",
    "\n",
    "We'll use the AutoModelForSequenceClassification to load from the MODEL_NAME (base model) for binary text classification"
   ],
   "metadata": {
    "id": "F3qhP7znnuII"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
   ],
   "metadata": {
    "id": "6RVADiiIngBS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "\n",
    "Create an optimizer and learning rate scheduler to fine-tune the model.\n",
    "\n",
    "We use the AdamW optimizer from PyTorch.\n"
   ],
   "metadata": {
    "id": "UX7MIhWjoBF7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "_J-tAXrdYgUW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Training Hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n"
   ],
   "metadata": {
    "id": "e5vUNAsm1b11"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)"
   ],
   "metadata": {
    "id": "ZO2SXeJ3oDan"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the default learning rate scheduler from Trainer:"
   ],
   "metadata": {
    "id": "ZhKNROluoyy5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "# number of warmup steps for learning rate scheduler\n",
    "warmup_steps=int((len(train_loader)/batch_size) * num_epochs * 0.2)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps\n",
    ")"
   ],
   "metadata": {
    "id": "J5SK-4IwoXCm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Specify the device to use a GPU if available"
   ],
   "metadata": {
    "id": "g9yoOZnSp09z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from accelerate.test_utils.testing import get_backend\n",
    "\n",
    "device, _, _ = get_backend() # automatically detects the device type (CUDA, CPU, XPU, MPS, etc.)\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "id": "LxTCFj7tpiOD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available and PyTorch can use it.\")\n",
    "else:\n",
    "    print(\"GPU is not available or PyTorch cannot use it.\")"
   ],
   "metadata": {
    "id": "RJVTOgi8qJwy"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the Model"
   ],
   "metadata": {
    "id": "a-oq19GGoXZh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ],
   "metadata": {
    "id": "s5Xpjq9WqloW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {
    "id": "AuLFGvYqrGIT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()\n",
    "\n",
    "# Instead of torch.save(model), this will save the model in a structured folder)\n",
    "#torch.save(model, f\"fake_news_detection\")\n",
    "model.save_pretrained(\"fake_news_classification\")\n",
    "tokenizer.save_pretrained(\"fake_news_classification\")"
   ],
   "metadata": {
    "id": "8RDSvk4Aq3D_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "KO8AiKCOtAr-"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
